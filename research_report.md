Guardian-AA Architecture Update: Integrating PoT Bootstrapping and Recursive ZKML
Recap of Original Guardian-AA ZK Stack and Limitations
Original Approach: The Guardian-AA system previously relied on a Halo2 + KZG proving stack (including EZKL-generated circuits) to produce zero-knowledge proofs of ML model inference on-device. Halo2 (a Plonkish SNARK from Zcash) with KZG commitments offers fast proof verification and small proofs, but it requires a trusted setup (Powers-of-Tau ceremony) for a maximum circuit size. In the original design, a universal Structured Reference String (SRS) was assumed to be generated (or re-used) to support the required circuit size, and the entire model’s inference was proven as one monolithic circuit. This had several limitations:
Trusted Setup Burden: A large one-time ceremony was needed to support the circuit’s maximal degree (number of constraints). For complex models, this means generating many powers-of-$\tau$, which is costly and logistically complex. If the model or circuit grew beyond the initial setup’s capacity, a new ceremony would be required – a significant friction for developers and users.
Prover Resource Constraints: Proving a large model in one shot on a mobile device is heavy. It demands substantial memory and time since all layers of the neural network are constrained in one circuit. This raised doubts about on-device proof generation feasibility without offloading to a server or using very optimized libraries.
Lack of Recursion/Modularity: The original stack did not exploit recursive proof composition. Without recursion, every time the model changed or a new input was processed, a full proof had to be generated from scratch. It was not easy to compose smaller proofs or reuse partial results, limiting scalability.
Model Size Limitations: Because of the above, there were practical limits on the size of ML models provable. If the Powers-of-Tau (PoT) setup only supported, say, up to $2^{15}$ constraints, it restricted the complexity of statements (model inference) that can be proven
ar5iv.org
. Using fewer powers-of-$\tau$ values means only smaller circuits (simpler models or lower precision) could be handled, unless a costly larger ceremony was performed.
In summary, while the Halo2+KZG+EZKL approach provided a workable starting point, its setup inefficiency and monolithic proving model posed challenges for scalability and user experience. The latest research offers solutions to these issues, as we detail next.
Incorporating Efficient Powers-of-Tau Bootstrapping (Universal SRS)
Key Idea: The paper “Powers of Tau Bootstrapping: Efficient Setup for ZKML and Beyond” introduces a system for efficiently generating and extending a universal SRS suitable for large-scale circuits (like those for ML models) without repeating onerous ceremonies for each project. In essence, it enables bootstrapping one trusted setup into another and amortizing the cost across many participants and applications. This directly addresses the setup efficiency problem:
Universal SRS (One-and-Done Setup): Instead of a circuit-specific setup, we adopt a universal PoT SRS that covers all circuits up to a high degree. This SRS can be shared across different models and proofs. The new approach makes it practical to support a very large number of powers-of-$\tau$ (hence very complex statements) in one ceremony
ar5iv.org
ar5iv.org
. For example, the research demonstrates a decentralized ceremony for up to $2^{15}$ powers-of-$\tau$ with significantly reduced cost, and suggests this can be scaled further
arxiv.org
. In Guardian-AA, we would target a universal SRS large enough for our longest model inference trace (plus some growth headroom), eliminating the need for redo setups when models evolve.
Bootstrapping & Extensibility: A highlight is that the phase-1 (PoT) ceremony itself can be bootstrapped rather than redone from scratch
fc25.ifca.ai
. In practice, this means we could start from an existing SRS and extend it with additional contributions to support more powers-of-$\tau$ as needed, instead of coordinating a brand new ceremony. Many projects already follow this “perpetual ceremony” model (e.g., Ethereum’s Perpetual Powers of Tau); the new protocol formalizes and improves it. For Guardian-AA, this means if future models require more complex circuits, we can simply add a round to the SRS generation (with a new random contribution or beacon) to increase its capacity
fc25.ifca.ai
, rather than running a separate setup. This preserves the “at least one honest contributor” security assumption while avoiding repetitive processes
fc25.ifca.ai
.
Decentralized & Low-Cost Setup: The paper’s system uses clever on-chain coordination to drastically cut the cost per contribution. Notably, it introduces a fraud-proof approach to validate contributions and a batching (aggregation) of multiple contributions into one update
ar5iv.org
ar5iv.org
. This achieved an $\sim$16× reduction in on-chain operations for a given SRS size (e.g. degree $2^{15}$)
arxiv.org
. The implication for Guardian-AA is that we (or the community) can run a large-scale ceremony with hundreds of contributors at minimal cost. More contributions = more security (only one needs to be honest), which is great for eliminating trust concerns. And because contributions can be batched, inviting large numbers of participants doesn’t bloat the cost linearly
arxiv.org
ar5iv.org
. In short, obtaining a robust SRS for our proving system is now cheaper and more accessible than before.
Improved UX for Developers: By adopting the above, the proving stack becomes easier to integrate for developers. They can simply download or derive the universal parameters (SRS) once and use them for all circuits (model versions, different verification circuits, etc.) up to the max size. This enhances the developer experience, as they no longer need to worry about setup ceremonies when tweaking a model or circuit – the universal SRS has them covered. It’s also positive for end-users: the parameters can be hard-coded or fetched within the app, and they carry the assurance of a widely participatory ceremony (minimizing trust in any single party).
Trade-offs: The universal SRS (especially if very large) means a larger parameter file to store or download on-device (potentially on the order of tens or hundreds of MB for very high degrees). However, thanks to bootstrapping, we can choose a just-sufficient size and extend it incrementally. Additionally, techniques like splitting the SRS (only loading needed segments) or using compression can mitigate the footprint. Overall, the benefits to scalability and avoiding repeated trusted setups outweigh this cost.
Recursive Proof Composition for ZKML
In parallel with a more flexible SRS, we introduce recursive proof composition into the Guardian-AA architecture to tackle prover constraints and scalability. Proof recursion means a proof can attest to the correctness of other proofs, allowing us to build complex proofs in stages (layers) rather than all at once. The latest research and industry experience (e.g. Halo 2, Nova, recursive Plonk variants) show that recursion is essential to efficiently prove very large statements – “proof recursion is almost the only way to prove huge and complicated statements”, as one overview notes. How we’ll use recursion in Guardian-AA:
Layered Circuit Design: We refactor the monolithic model circuit into multiple smaller circuits (e.g., one per model layer or per group of layers). Each circuit proves a portion of the computation (e.g., a few neural network layers’ forward pass) and outputs an intermediate hash or commitment of its results. Instead of immediately combining all layers, the device will generate proofs for each chunk of the model execution sequentially. For instance, if the model has layers [A, B, C, D], we might prove [A,B] in one circuit and [C,D] in another, or even each layer separately, depending on complexity. Each proof includes as a public output the intermediate tensor that will go into the next layer.
Recursive Aggregator Circuit: A final verifier circuit (aggregator) takes the intermediate outputs and the proofs of each sub-circuit as inputs, and it verifies those proofs within a new SNARK, outputting a single combined proof that “the entire model was executed correctly.” This approach leverages the universal SRS’s ability to support one more layer of circuit dedicated to verification logic. Because all circuits share the same SRS, the aggregator can easily validate KZG-based proofs from the sub-circuits as part of its arithmetic constraints. Recent techniques (Halo 2’s recursive verifier and variants like Goblin Plonk) significantly reduce the overhead of verifying a pairing-based proof inside a circuit – e.g., 64 scalar multiplications needed for verifying a proof can be done with only ~7k constraints instead of ~300k by using optimized custom gates
hackmd.io
. This means the recursion overhead is manageable, adding only a few thousand constraints per inner proof checked.
Resource-Constrained Prover Strategy: The benefit of this staged approach is that the mobile device (prover) never has to handle the full model constraints at once. It can prove chunk by chunk, potentially freeing memory after each chunk, which lowers peak RAM usage. The final aggregation step could even be offloaded to a more powerful server if needed (since it doesn’t see private data, only proofs and public signals). In fact, one can adopt a model similar to Aztec’s “Goblin Plonk” approach: the phone produces a partially aggregated proof that might be larger or less optimized, and then a server or L2 sequencer takes that and wraps it in one more proof to compress it fully
hackmd.io
. This two-tier recursion (user side and server side) balances user effort vs. proof size. In any case, a resource-limited prover can utilize multiple layers of recursion, leaving the heavy lifting of final compression to a more capable node
hackmd.io
. This is ideal for Guardian-AA’s scenario where user devices vary in power.
Scalability and Model Provability: Recursive composition vastly improves scalability. Now, larger models that were previously infeasible to prove on-device become provable by splitting across circuits. The approach also future-proofs the system: if models grow in complexity (more layers or parameters), we can simply add more intermediate proofs or recursion depth, rather than blowing up a single circuit beyond what hardware can support. In effect, recursion provides modularity: each circuit can even be updated or optimized independently (e.g., if one segment of the model changes, only that circuit and the aggregator need updates, not the whole pipeline). This aligns with the “and beyond” promise – any complex computation can be decomposed and verified with unlimited scalability by recursive proof-carrying techniques
medium.com
hackmd.io
.
Trade-offs: Introducing recursion does add overhead in proof generation time – multiple proofs must be generated and an aggregator proof computed – but thanks to the improved methods (Halo 2’s efficient verifier circuits, etc.), the overall overhead is kept reasonable. Verification time for the verifier of the verifier (i.e., checking the final proof) remains succinct (just like a single proof, a few pairings or group operations). The final proof size might increase slightly (e.g., containing proofs of proofs) but is still constant-sized and small (kilobytes). We judge these trade-offs to be acceptable given the enormous gains in prover feasibility and flexibility. Notably, verification costs on-chain or on the client remain low and essentially constant, since they only verify one succinct proof at the end, regardless of how complex the underlying computation was. This is the magic of recursion: unlimited computation attested by one small proof
medium.com
.
Impact on On-Device Proving and UX
By combining the above advancements, on-device proving becomes much more feasible and user-friendly:
Lower Memory & CPU Burden: A smartphone can now prove smaller chunks one at a time, which avoids the memory blow-up of a single giant circuit. For example, if each sub-circuit is bounded to, say, 50k constraints, the phone only handles that at once (which might take several seconds and a few hundred MB of RAM, doable on high-end devices), instead of a monolithic 1 million constraint circuit (which could take minutes and gigabytes of RAM, likely impossible on mobile). This chunking is especially important for models with many layers or large matrices. Users are less likely to experience app crashes or excessive delays.
Gradual Proof Generation UX: We could even provide feedback or streaming proof generation – e.g., “Proving layer 1...2...3...” – giving a sense of progress rather than one long stall. If a proof segment fails, it can be retried for that segment alone. This incremental approach improves the user experience, as the process is more transparent and resilient.
Energy Considerations: Shorter proving steps allow the device to cool down or the user to pause between steps if needed, avoiding a single long high-CPU burst that drains battery or heats the device too much. If the final aggregation is offloaded to a server or done when the device is plugged in, the on-device energy usage is further minimized. From the user’s perspective, generating a ZK proof for an ML inference moves closer to a background task that doesn’t disrupt normal device use.
Verification Costs: Whether the final proof is verified on-chain (e.g., a smart contract) or locally by a verifier app, the cost remains low. In an on-chain scenario, we still submit a single succinct proof (e.g., Halo2 proof verification might cost a few pairing ops ~ a few tens of thousands of gas, which is fixed). This enhances UX because it keeps any on-chain interaction cheap and fast, even if the underlying model is huge. In off-chain verification (e.g., a user verifying the app’s proof), it means quick confirmation of authenticity.
Security and Trust: The improvements do not compromise security—if anything, they enhance it. The SRS bootstrapping ensures a high-security parameter (with many contributions making it near-impossible that the trapdoor wasn’t destroyed)
ar5iv.org
ar5iv.org
. Recursion, while complex, relies on well-studied assumptions (if each proof system is secure, the recursion remains secure). By structuring the proof in layers, we also reduce the chance of a single bug invalidating the entire proof: even if one circuit had an issue, the other proofs and final check provide additional consistency checks (each verifier circuit re-checks the prior proofs). This layered approach aligns with a “defense-in-depth” philosophy for verification.
Developer Integration and Full-Stack Modifications
Adopting the Powers-of-Tau bootstrapping and recursive proving strategies will require some changes to our full-stack plan and components, but each change is aimed at improving developer and user outcomes:
Proving System Backend: We will extend our proving backend to support recursive circuits. With Halo2, this means leveraging the Pallas/Vesta cycle (the Pasta curves) to create a recursive verifier circuit. We’ll integrate the Halo2 recursive proof gadgets (as documented in Zcash’s Halo2 book) or use community libraries if available. If using EZKL, we’ll check its support for outputting recursive circuits or we may need to write a custom aggregator circuit in Halo2 manually. This is a new development milestone: Milestone 1: Implement and test recursive verifier circuit for sub-proofs. We expect to use a template provided by Halo2’s examples, adapting it to our specific circuits. In parallel, we’ll incorporate support for the universal SRS parameters – likely by allowing our proving tool to ingest a common reference string file. Since the Halo2 KZG setup can be generated by the new ceremony, developers simply need to ensure they load the correct SRS (e.g., via an environment variable or configuration pointing to the params file).
Circuit Refactoring (EZKL Model Split): We will refactor the EZKL-captured model circuit into modular circuits. EZKL currently can compile an entire ONNX model to one circuit; we may enhance it or run it per layer. If EZKL doesn’t natively split circuits, we might use it to generate sub-circuits by slicing the model graph manually. This requires determining the intermediate outputs to pass between circuits (likely as public inputs to the next circuit and public outputs of the previous, so that the aggregator can tie them together). Milestone 2: Prototype multi-circuit model proving: e.g., prove first N layers and output their result, then consume that in proving next N layers. This will also involve writing intermediate data to disk or memory in a serialized form that becomes input for the next proof.
Proof Aggregation Circuit: Develop the aggregator SNARK circuit that takes the public outputs of all segments and the proofs of each segment, and verifies all of them. This component might use pairings and multiexponentiation logic inside (for KZG-based proof verification), which is complex – we will likely use existing Halo2 chips or an “accumulator” strategy from Halo (Halo 2 uses an accumulation scheme to verify proofs incrementally with logarithmic checks
zcash.github.io
zcash.github.io
). The end result is a single proof attesting that “all segment proofs are valid and their inputs/outputs line up correctly.” Milestone 3: Build and test aggregator circuit verifying dummy sub-proofs, then integrate real ones.
Integration of Bootstrapped SRS: On the ceremony side, instead of a developer-run local setup, we’ll partake in or initiate a bootstrapped PoT ceremony. Ideally, we can utilize an existing large universal SRS (for example, Ethereum’s recent ceremony outputs, or the one described in the paper). If none fits our needs exactly, we will run our own but using the paper’s methods:
Use the fraud-proof + batch update approach to allow our community or stakeholders to contribute to the randomness with minimal cost
ar5iv.org
ar5iv.org
.
We plan to integrate a beacon randomness (e.g., hash of a future block) as an additional final contribution to cement the unpredictability of $\tau$.
Once complete, the SRS (a list of G1 and G2 points) will be published for anyone to download.
Milestone 4: Guardian-AA Ceremony (if needed): Execute an efficient PoT ceremony up to the required degree. (If we target circuits of size ~100k constraints, $2^{17}$ or $2^{18}$ powers might suffice; we’ll overshoot to be safe, perhaps $2^{20}$, and thanks to the new protocol this is feasible in a decentralized way.)
Optional: Alternative Proof Systems: The paper also hints at using the new SRS for ZKML and beyond – i.e., our system could later switch to a proof system that doesn’t need a toxic waste at all by using the SRS as a base for commit-and-prove. For instance, the Artemis CP-SNARK approach could be considered: Artemis can work with any polynomial commitment (including IPA or FRI which don’t need trusted setup)
arxiv.org
. In the near term we stick with Halo2+KZG (for its maturity and performance), but the architecture is now flexible: we could swap in a no-trusted-setup backend (like Halo2 with IPA commitments, or Nova folding scheme) in future without redesigning the whole system. This is because the recursion and modular circuits are high-level design choices, not tied to KZG specifically. As evidence of feasibility, Artemis showed that for a large model like VGG, using commit-and-prove can reduce overhead of commitment checks from 11.5× to 1.2×
arxiv.org
– a huge improvement in proving time. Such optimizations might be integrated into Guardian-AA down the road, improving performance without new trusted setups required.
Testing and Security Audits: Introducing recursion adds complexity, so an important step is rigorous testing. Milestone 5: End-to-end test on a simple model with recursion enabled (e.g., a 2-layer network split into 2 circuits + aggregator). Verify the final proof both on-chain (with a verifier contract) and off-chain (with the Halo2 verifier API). We will also carefully audit the circuits (especially the verifier circuit) to ensure no loopholes – this is critical since a bug there could falsely validate a bad proof. The bootstrapped SRS’s security relies on at least one honest contributor; we’ll document the ceremony contributions for transparency and possibly publish a report to assure users that the Guardian-AA parameters follow the new state-of-the-art best practices for trustlessness
ar5iv.org
.
Updated Architecture Diagram and Flow
System Overview: The architecture now has a multi-layer proof generation pipeline and a streamlined trusted setup component:
Mobile App (Prover): Uses EZKL (or similar) to generate witness values for each model layer. It then runs the ZKP proving algorithm segment by segment. For each segment it loads the universal SRS (just once at start) and produces a proof $\pi_i$. After all segments, it may either itself run the final aggregation proving to get $\Pi_{\text{final}}$ or send the intermediate proofs to a server for aggregation. The app finally obtains $\Pi_{\text{final}}$, a succinct proof of the whole inference.
Verification Smart Contract (Verifier): Unchanged in interface – it simply needs the ability to verify $\Pi_{\text{final}}$ using the same SRS’s verification key. From the blockchain’s perspective, nothing has changed except possibly using a larger verifying key (if the final circuit is larger than the old monolith, though in practice it might be smaller). The gas cost to verify remains on the order of a few pairings. We ensure that $\Pi_{\text{final}}$ is as small and quick to verify as a normal Plonk proof, thanks to the recursive composition technique compressing all the work.
Developer Workflow: When updating the ML model or parameters, the developer does not perform a new trusted setup. They either ensure the model still fits in the current SRS’s capacity or, if it doesn’t, they trigger the PoT bootstrapping by organizing a few new contributions (which can even be done permissionlessly via a contract as the paper outlines). This is a minor process that can be done asynchronously. The dev then updates the circuit definitions (maybe splitting differently if needed) and redeploys the verifier with the new circuit’s verifying key (still derived from the same universal SRS). The heavy lifting of the SRS generation is already done and remains valid. This greatly accelerates development cycles – changes in model architecture or new features won’t be bottlenecked by waiting for a months-long ceremony or using suboptimal proving schemes.
Diagram (Conceptual):
scss
Copy
Edit
[User Device]
├─▶ Circuit 1 (Layers 1-3) – proves → π1
├─▶ Circuit 2 (Layers 4-6) – proves → π2
├─▶ ...
└─▶ Circuit N (Layers ... ) – proves → πN
└─▶ Aggregator Circuit – verifies {π1...πN} → outputs Π_final
└─▶ [Smart Contract] verifies Π_final and accepts result
(All circuits share the same Universal SRS parameters. The aggregator circuit contains the verification logic for $\pi_1...\pi_N$.) In the above flow, the device sequentially generates $\pi_1, \pi_2, ..., \pi_N$, using outputs of one as inputs to the next. Then either the device or an external service runs the Aggregator Circuit to produce $\Pi_{\text{final}}$. Only $\Pi_{\text{final}}$ is submitted to the blockchain (or to the relying party), which then checks it and thus validates the entire computation at once.
Benefits, Trade-offs, and Conclusion
By integrating the insights from efficient PoT bootstrapping and recursive proof composition, the Guardian-AA system achieves greater scalability, flexibility, and user-friendliness:
Setup Efficiency: We remove the need for repetitive trusted setups. A one-time high-quality SRS (potentially contributed to by dozens or hundreds of participants globally) suffices for all our needs, and it can be extended securely if those needs grow. This lowers barriers to entry for both developers and external contributors (no specialized ceremonies per app). The all-but-one-honest security of the ceremony is maintained while making participation trivial and inexpensive
arxiv.org
ar5iv.org
.
Proof Performance: Through recursion, we expect to handle larger ML models without a combinatorial explosion in proving time or failure on low-memory devices. Proving time might even improve for a given model because of better cache utilization on smaller circuits and potential parallelism (e.g., if some segments are independent, they could be proven in parallel on multi-core devices or distributed among devices in future). The overall prover time will somewhat increase due to the extra aggregation step, but this is a conscious trade for vastly improved feasibility. Moreover, if needed, the heavy aggregation step can run on a cloud verifier, allowing the user’s device to do just the light work and still achieve end-to-end ZK verification.
Verification Cost: Remains succinct and low. Whether one large proof or a recursively aggregated proof, the verification is a constant number of operations. In our case, a Halo2 proof verification is maybe ~check 3 pairings and some MSMs. With a universal SRS, verifying a proof of a given size is unchanged. We ensure the final proof is of similar size to a non-recursive one, so there’s little impact on on-chain costs or bandwidth.
Developer & User Experience: Perhaps most importantly, these changes make the system more developer-friendly (no waiting on trusted setup, easier to incorporate changes, reuse of common tools) and user-friendly (faster, more reliable on-device proving, with the option for hybrid proving if needed). By clarifying and modularizing the ZK stack, we also make it easier for new contributors to focus on specific parts (e.g., someone can optimize just the aggregator circuit or just the model circuit without touching the rest).
Trade-offs and Future Considerations: The main trade-off is added complexity in the implementation and proving pipeline. We’ve introduced multiple circuits and a non-trivial verifier circuit. This increases the surface for potential bugs – extensive testing and possibly formal verification of the recursion logic is warranted. Also, the universal SRS, if compromised (e.g., if all ceremony participants colluded, which is extremely unlikely), would compromise all proofs derived from it. However, broad participation makes this practically infeasible, and using a random beacon as final entropy further secures it
fc25.ifca.ai
. Users must be updated once to download the new SRS parameters file, which is a one-time inconvenience we will manage via the app update process. Looking ahead, the incorporation of these state-of-the-art methods positions Guardian-AA on the cutting edge of ZKML technology. It aligns the project with the latest research that multi-layer recursion and universal setup are the way to achieve practical, scalable verifiable AI. By adopting Powers-of-Tau bootstrapping and recursive proofs now, we set the foundation for further enhancements (like zero-knowledge model training proofs, real-time verification, or supporting even larger AI models) without fundamental changes to the architecture. In summary, this update significantly strengthens the proving stack – making it more efficient in setup, more powerful in capability, and smoother in integration – thus empowering Guardian-AA to deliver a secure, scalable, and user-friendly verifiable AI experience for the community. Sources:
Ng et al., “Lite-PoT: Practical Powers-of-Tau Setup Ceremony,” arXiv 2503.04549
arxiv.org
ar5iv.org
ar5iv.org
ar5iv.org
. (Efficient decentralized ceremony, supports larger SRS for more complex circuits)
Halo2 Book – “Recursion in Halo2,” Zcash (2023)
zcash.github.io
zcash.github.io
. (Describes accumulating pairing checks for recursive proof verification)
Aztec team, “Goblin Plonk: lazy recursive proof composition,” HackMD (2023)
hackmd.io
hackmd.io
. (Technique enabling resource-constrained provers to delegate heavy verification to an aggregator, with concrete cost estimates)
Lycklama et al., “Artemis: Efficient Commit-and-Prove SNARKs for zkML,” arXiv 2409.12055 (2023)
arxiv.org
arxiv.org
. (Demonstrates eliminating trusted setup dependence and improving large-model proving overhead via commitment optimizations)